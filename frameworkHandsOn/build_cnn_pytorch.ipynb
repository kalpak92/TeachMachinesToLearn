{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Build PyTorch CNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "__ML Pipeline__: Prepare data -> __build model__ -> train model -> analyze model's results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "To build neural networks in PyTorch, we extend the `torch.nn.Module` PyTorch class. This means we need to utilize a little bit of object oriented programming (OOP) in Python."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## OOP Review\n",
    "\n",
    "When we’re writing programs or building software, there are two key components, code and data. With object oriented programming, we orient our program design and structure around objects.\n",
    "\n",
    "Objects are defined in code using classes. A class defines the object's specification or spec, which specifies what data and code each object of the class should have.\n",
    "\n",
    "When we create an object of a class, we call the object an instance of the class, and all instances of a given class have two core components:\n",
    "- Methods (code)\n",
    "- Attributes (data)\n",
    "\n",
    "The methods represent the code, while the attributes represent the data, and so the methods and attributes are defined by the class.\n",
    "\n",
    "In a given program, many objects, a.k.a instances of a given class, can exist simultaneously, and all of the instances will have the same available attributes and the same available methods. They are uniform from this perspective.\n",
    "\n",
    "The difference between objects of the same class is the values contained within the object for each attribute. Each object has its own attribute values. These values determine the internal state of the object. The code and data of each object is said to be encapsulated within the object."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lizard:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def set_name(self, name):\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Deer\n"
     ]
    }
   ],
   "source": [
    "lizard = Lizard('Deer')\n",
    "print(lizard.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DL\n"
     ]
    }
   ],
   "source": [
    "lizard.set_name('DL')\n",
    "print(lizard.name)"
   ]
  },
  {
   "source": [
    "## `torch.nn`\n",
    "\n",
    "As we know, deep neural networks are built using multiple layers. This is what makes the network deep. Each layer in a neural network has two primary components:\n",
    "\n",
    "* A transformation (code)\n",
    "* A collection of weights (data)\n",
    "\n",
    "Within the `nn` package, there is a class called `Module`, and it is the __base class__ for all of neural network modules which includes layers.\n",
    "\n",
    "This means that all of the layers in PyTorch extend the `nn.Module` class and inherit all of PyTorch’s built-in functionality within the `nn.Module` class. \n",
    "\n",
    "In OOP this concept is known as __inheritance__."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "source": [
    "### `forward()` method\n",
    "\n",
    "When we pass a tensor to our network as input, the __tensor flows__ forward though each layer transformation until the tensor reaches the output layer. This process of a tensor flowing forward though the network is known as a __forward pass__.\n",
    "\n",
    "Each layer has its own transformation (code) and the tensor passes forward through each layer. The composition of all the individual layer forward passes defines the overall forward pass transformation for the network. The goal of the overall transformation is to transform or map the input to the correct prediction output class, and during the training process, the layer weights (data) are updated in such a way that cause the mapping to adjust to make the output closer to the correct prediction. This is achieved efficiently by __backpropagation__.\n",
    "\n",
    "What this all means is that, every PyTorch `nn.Module` has a `forward()` method, and so when we are building layers and networks, we must provide an implementation of the `forward()` method. The forward method is the actual transformation."
   ],
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "source": [
    "### `torch.nn.functional`\n",
    "\n",
    "When we implement the `forward()` method of our `nn.Module` subclass, we will typically use functions from the `nn.functional` package. This package provides us with many neural network operations that we can use for building layers. In fact, many of the `nn.Module` layer classes use `nn.functional` functions to perform their operations.\n",
    "\n",
    "The `nn.functional` package contains methods that __subclasses__ of `nn.Module` use for implementing their `forward()` functions. One reason for this is that during backpropagation, the network must perform a __symbolic differentiation__ of the operations involved in the layers to calculate the gradient of the loss with respect to the weights."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Building a Neural Network in PyTorch\n",
    "\n",
    "We now have enough information to provide an outline for building neural networks in PyTorch. The steps are as follows:\n",
    "\n",
    "Short version:\n",
    "\n",
    "- Extend the `nn.Module` base class.\n",
    "- Define layers as class attributes.\n",
    "- Implement the `forward()` method.\n",
    "\n",
    "\n",
    "More detailed version:\n",
    "\n",
    "- Create a neural network class that extends the `nn.Module` base class.\n",
    "- In the class constructor, define the network’s layers as class attributes using pre-built layers from `torch.nn`.\n",
    "- Use the network’s layer attributes as well as operations from the `nn.functional` API to define the network’s forward pass."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a trivial neural network (zero layers)\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init()\n",
    "        self.layer = None\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = self.layer(t)\n",
    "        return t\n"
   ]
  },
  {
   "source": [
    "Let’s replace this now with some real layers that come pre-built for us from PyTorch's `nn` library. We’re building a CNN, so the two types of layers we'll use are linear layers and convolutional layers."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, t):\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "network = Network()\n",
    "network"
   ]
  },
  {
   "source": [
    "We used the abbreviation `fc` in `fc1` and `fc2` because linear layers are also called fully connected layers. They also have a third name that we may hear sometimes called dense. So linear, dense, and fully connected are all ways to refer to the same type of layer. PyTorch uses the word linear, hence the `nn.Linear` class name.\n",
    "\n",
    "We used the name `out` for the last linear layer because the last layer in the network is the output layer.\n",
    "\n",
    "The above neural net has three hyperparameters that need to be manually specified:\n",
    "* `kernel_size.`  size of each convolutional filter\n",
    "* `out_channels` number of filters in the convolutional layer \n",
    "* `out_features` size of output tensor, i.e. the number of neurons in the dense layer\n",
    "\n",
    "Having `out_features=10` on the final output layer is a data dependent hyperparameter, i.e. fixed due to the nature of the problem."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### CNN Layer Parameters\n",
    "\n",
    "### Parameters vs Arguments\n",
    "\n",
    "Well parameters are used in function definitions as place-holders while arguments are the actual values that are passed to the function. The parameters can be thought of as local variables that live inside a function.\n",
    "\n",
    "In our network's case, the names are the parameters and the values that we have specified are the arguments."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Two Types of Parameters\n",
    "\n",
    "To better understand the argument values for these parameters, let's consider two categories or types of parameters that we used when constructing our layers.\n",
    "\n",
    "- Hyperparameters\n",
    "- Data dependent hyperparameters\n",
    "\n",
    "A lot of terms in deep learning are used loosely, and the word parameter is one of them. Try not to let it through you off. The main thing to remember about any type of parameter is that the parameter is a place-holder that will eventually hold or have a value.\n",
    "\n",
    "The goal of these particular categories is to help us remember how each parameter's value is decided.\n",
    "\n",
    "When we construct a layer, we pass values for each parameter to the layer’s constructor. With our convolutional layers have three parameters and the linear layers have two parameters.\n",
    "\n",
    "- Convolutional layers\n",
    "    - in_channels\n",
    "    - out_channels  - Sets the number of filters. One filter produces one output channel.\n",
    "    - kernel_size   - Sets the filter size. The words kernel and filter are interchangeable.\n",
    "\n",
    "- Linear layers\n",
    "    - in_features\n",
    "    - out_features - Sets the size of the output tensor.\n",
    "\n",
    "#### Hyperparameters\n",
    "In general, hyperparameters are parameters whose values are chosen manually and arbitrarily.\n",
    "\n",
    "As neural network programmers, we choose hyperparameter values mainly based on trial and error and increasingly by utilizing values that have proven to work well in the past. For building our CNN layers, these are the parameters we choose manually.\n",
    "\n",
    "- `kernel_size`\n",
    "- `out_channels`\n",
    "- `out_features`\n",
    "\n",
    "This means we simply choose the values for these parameters. In neural network programming, this is pretty common, and we usually test and tune these parameters to find values that work best.\n",
    "\n",
    "One pattern that shows up quite often is that we increase our out_channels as we add additional conv layers, and after we switch to linear layers we shrink our out_features as we filter down to our number of output classes.\n",
    "\n",
    "#### Data Dependent Hyperparameters\n",
    "Data dependent hyperparameters are parameters whose values are dependent on data. The first two data dependent hyperparameters that stick out are the `in_channels` of the first convolutional layer, and the `out_features` of the output layer.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "| Layer \t| Param name   \t| Param value \t| The param value is                                      \t|\n",
    "|-------\t|--------------\t|-------------\t|---------------------------------------------------------\t|\n",
    "| conv1 \t| in_channels  \t| 1           \t| the number of color channels in the input image.        \t|\n",
    "| conv1 \t| kernel_size  \t| 5           \t| a hyperparameter.                                       \t|\n",
    "| conv1 \t| out_channels \t| 6           \t| a hyperparameter.                                       \t|\n",
    "| conv2 \t| in_channels  \t| 6           \t| the number of out_channels in previous layer.           \t|\n",
    "| conv2 \t| kernel_size  \t| 5           \t| a hyperparameter.                                       \t|\n",
    "| conv2 \t| out_channels \t| 12          \t| a hyperparameter (higher than previous conv layer).     \t|\n",
    "| fc1   \t| in_features  \t| 12*4*4      \t| the length of the flattened output from previous layer. \t|\n",
    "| fc1   \t| out_features \t| 120         \t| a hyperparameter.                                       \t|\n",
    "| fc2   \t| in_features  \t| 120         \t| the number of out_features of previous layer.           \t|\n",
    "| fc2   \t| out_features \t| 60          \t| a hyperparameter (lower than previous linear layer).    \t|\n",
    "| out   \t| in_features  \t| 60          \t| the number of out_channels in previous layer.           \t|\n",
    "| out   \t| out_features \t| 10          \t| the number of prediction classes.                       \t|"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}