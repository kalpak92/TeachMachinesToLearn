{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# TensorBoard with PyTorch - Metrics Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, channels=1): # default grayscale\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=channels, out_channels=6, kernel_size=5) \n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120) # ((28-5+1)/2 -5 +1)/2 = 4\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):        \n",
    "        # hidden conv layers, conv w/ relu activation -> max pool\n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # hidden fully connected layers\n",
    "        t = t.reshape(-1, 12*4*4) # flatten\n",
    "        t = F.relu(self.fc1(t))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        \n",
    "        # output layer\n",
    "        t = self.out(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return (preds.argmax(dim=1) == labels).sum().item()"
   ]
  },
  {
   "source": [
    "## TensorBoard: TensorFlow's Visualization Toolkit\n",
    "TensorBoard provides the visualization and tooling needed for machine learning experimentation:\n",
    "\n",
    "- Tracking and visualizing metrics such as loss and accuracy\n",
    "- Visualizing the model graph (ops and layers)\n",
    "- Viewing histograms of weights, biases, or other tensors as they change over time\n",
    "- Projecting embeddings to a lower dimensional space\n",
    "- Displaying images, text, and audio data\n",
    "- Profiling TensorFlow programs\n",
    "- And much more"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform.Compose([\n",
    "        transform.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)"
   ]
  },
  {
   "source": [
    "## Network Graph And Training Set Images\n",
    "\n",
    "The `SummaryWriter` class comes with a bunch of method that we can call to selectively pick and choose which data we want to be available to TensorBoard. \n",
    "\n",
    "We'll start by first by passing our network and a batch of images to the writer."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = SummaryWriter()\n",
    "\n",
    "\n",
    "network = Network()\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.add_image('images', grid)\n",
    "tb.add_graph(network, images)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 0 total_correct: 41126 loss: 390.1810419559479\n",
      "epoch 1 total_correct: 47761 loss: 254.7536964416504\n",
      "epoch 2 total_correct: 49847 loss: 219.45858508348465\n",
      "epoch 3 total_correct: 50799 loss: 198.94785119593143\n",
      "epoch 4 total_correct: 51440 loss: 185.06912292540073\n",
      "epoch 5 total_correct: 51822 loss: 175.7590073943138\n",
      "epoch 6 total_correct: 52123 loss: 167.45953722298145\n",
      "epoch 7 total_correct: 52458 loss: 160.68897560238838\n",
      "epoch 8 total_correct: 52626 loss: 156.17585119605064\n",
      "epoch 9 total_correct: 52874 loss: 151.31312596797943\n"
     ]
    }
   ],
   "source": [
    "# Compile network\n",
    "network = Network()\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "# Initialize tensorboard\n",
    "tb = SummaryWriter()            # from torch.utils.tensorboard import SummaryWriter\n",
    "tb.add_image('images', grid)\n",
    "tb.add_graph(network, images)\n",
    "\n",
    "\n",
    "# Training\n",
    "for epoch in range(10): \n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        images, labels = batch \n",
    "        preds = network(images)\n",
    "        \n",
    "        loss = F.cross_entropy(preds, labels) # loss function\n",
    "        optimizer.zero_grad()                 # set all gradients to zero\n",
    "        \n",
    "        loss.backward()         # calculate gradients, training points are supply constants\n",
    "        optimizer.step()        # update weights to minimize loss (accdg to adam)\n",
    "\n",
    "        total_loss += loss.item() \n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "    tb.add_scalar('Loss', total_loss, epoch)\n",
    "    tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "    tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "\n",
    "    tb.add_histogram('conv1.bias', network.conv1.bias, epoch)\n",
    "    tb.add_histogram('conv1.weight', network.conv1.weight, epoch)\n",
    "    tb.add_histogram('conv1.weight.grad', network.conv1.weight.grad, epoch)\n",
    "\n",
    "    print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "\n",
    "tb.close()"
   ]
  },
  {
   "source": [
    "## Hyperparameter Tuning and Experimenting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    lr = [.01, .001],\n",
    "    batch_size = [16, 128, 1024],\n",
    "    shuffle = [True, False]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[0.01, 0.001], [16, 128, 1024], [True, False]]"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "param_values = [v for v in parameters.values()]\n",
    "param_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.01 16 True\n0.01 16 False\n0.01 128 True\n0.01 128 False\n0.01 1024 True\n0.01 1024 False\n0.001 16 True\n0.001 16 False\n0.001 128 True\n0.001 128 False\n0.001 1024 True\n0.001 1024 False\n"
     ]
    }
   ],
   "source": [
    "for lr, batch_size, shuffle in product(*param_values):\n",
    "    print(lr, batch_size, shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 0 total_correct: 44622 loss: 40696.588181972504\n",
      "epoch 1 total_correct: 47819 loss: 32704.234094321728\n",
      "epoch 2 total_correct: 48305 loss: 31529.556753486395\n",
      "epoch 3 total_correct: 48796 loss: 30624.589919894934\n",
      "epoch 4 total_correct: 48982 loss: 30358.130439311266\n",
      "epoch 5 total_correct: 49110 loss: 29695.127415567636\n",
      "epoch 6 total_correct: 49046 loss: 29879.626960217953\n",
      "epoch 7 total_correct: 49303 loss: 29182.038885638118\n",
      "epoch 8 total_correct: 49146 loss: 30156.863276034594\n",
      "epoch 9 total_correct: 49315 loss: 29328.800338461995\n",
      "epoch 0 total_correct: 46608 loss: 35205.80108290911\n",
      "epoch 1 total_correct: 49715 loss: 28250.308654636145\n",
      "epoch 2 total_correct: 50200 loss: 27314.599574416876\n",
      "epoch 3 total_correct: 50442 loss: 26323.78204035759\n",
      "epoch 4 total_correct: 50295 loss: 27272.679124072194\n",
      "epoch 5 total_correct: 50515 loss: 26456.09761375189\n",
      "epoch 6 total_correct: 50658 loss: 26297.1187017411\n",
      "epoch 7 total_correct: 50297 loss: 27639.12085402757\n",
      "epoch 8 total_correct: 50522 loss: 26682.895561397076\n",
      "epoch 9 total_correct: 50762 loss: 25968.264598697424\n",
      "epoch 0 total_correct: 46682 loss: 34948.836099624634\n",
      "epoch 1 total_correct: 51129 loss: 23903.354749679565\n",
      "epoch 2 total_correct: 51923 loss: 21694.34476661682\n",
      "epoch 3 total_correct: 52240 loss: 20681.779010772705\n",
      "epoch 4 total_correct: 52572 loss: 19758.127634048462\n",
      "epoch 5 total_correct: 52789 loss: 19254.045948028564\n",
      "epoch 6 total_correct: 52967 loss: 18711.41085243225\n",
      "epoch 7 total_correct: 53102 loss: 18361.78508758545\n",
      "epoch 8 total_correct: 53036 loss: 18450.567848205566\n",
      "epoch 9 total_correct: 53254 loss: 17973.707275390625\n",
      "epoch 0 total_correct: 46847 loss: 34594.83964538574\n",
      "epoch 1 total_correct: 51510 loss: 22774.631818771362\n",
      "epoch 2 total_correct: 52379 loss: 20416.099170684814\n",
      "epoch 3 total_correct: 52590 loss: 19895.572484970093\n",
      "epoch 4 total_correct: 52902 loss: 18961.56880760193\n",
      "epoch 5 total_correct: 53132 loss: 18369.47230529785\n",
      "epoch 6 total_correct: 53251 loss: 17904.082127571106\n",
      "epoch 7 total_correct: 53407 loss: 17674.123783111572\n",
      "epoch 8 total_correct: 53473 loss: 17348.018392562866\n",
      "epoch 9 total_correct: 53619 loss: 17289.06837272644\n",
      "epoch 0 total_correct: 33860 loss: 68195.94500732422\n",
      "epoch 1 total_correct: 46872 loss: 34383.03689575195\n",
      "epoch 2 total_correct: 49487 loss: 28267.97900390625\n",
      "epoch 3 total_correct: 51036 loss: 24560.414672851562\n",
      "epoch 4 total_correct: 51866 loss: 22451.052276611328\n",
      "epoch 5 total_correct: 52288 loss: 21183.99737548828\n",
      "epoch 6 total_correct: 52546 loss: 20401.139282226562\n",
      "epoch 7 total_correct: 52909 loss: 19621.638580322266\n",
      "epoch 8 total_correct: 53159 loss: 18885.24006652832\n",
      "epoch 9 total_correct: 53376 loss: 18234.448287963867\n",
      "epoch 0 total_correct: 35585 loss: 62833.90496826172\n",
      "epoch 1 total_correct: 46540 loss: 34546.29177856445\n",
      "epoch 2 total_correct: 49420 loss: 28681.825164794922\n",
      "epoch 3 total_correct: 50792 loss: 25157.3349609375\n",
      "epoch 4 total_correct: 51386 loss: 23369.65655517578\n",
      "epoch 5 total_correct: 51912 loss: 21940.474151611328\n",
      "epoch 6 total_correct: 52252 loss: 20876.093963623047\n",
      "epoch 7 total_correct: 52512 loss: 20127.935089111328\n",
      "epoch 8 total_correct: 52846 loss: 19403.243927001953\n",
      "epoch 9 total_correct: 53037 loss: 18811.824432373047\n",
      "epoch 0 total_correct: 45625 loss: 38022.42115944624\n",
      "epoch 1 total_correct: 50875 loss: 24782.03725489974\n",
      "epoch 2 total_correct: 52029 loss: 21578.939826145768\n",
      "epoch 3 total_correct: 52652 loss: 19751.839117251337\n",
      "epoch 4 total_correct: 53089 loss: 18498.049694854766\n",
      "epoch 5 total_correct: 53401 loss: 17461.32357485406\n",
      "epoch 6 total_correct: 53761 loss: 16607.148348968476\n",
      "epoch 7 total_correct: 53966 loss: 15905.771736968309\n",
      "epoch 8 total_correct: 54273 loss: 15247.268649184145\n",
      "epoch 9 total_correct: 54426 loss: 14671.573924092576\n",
      "epoch 0 total_correct: 46749 loss: 34925.655714571476\n",
      "epoch 1 total_correct: 51787 loss: 22510.252998948097\n",
      "epoch 2 total_correct: 52786 loss: 19652.992182977498\n",
      "epoch 3 total_correct: 53330 loss: 17898.27398853749\n",
      "epoch 4 total_correct: 53798 loss: 16620.51569226384\n",
      "epoch 5 total_correct: 54096 loss: 15665.784524912946\n",
      "epoch 6 total_correct: 54368 loss: 14950.929988589138\n",
      "epoch 7 total_correct: 54669 loss: 14225.97527953703\n",
      "epoch 8 total_correct: 54800 loss: 13688.51968775643\n",
      "epoch 9 total_correct: 55068 loss: 13078.283795169555\n",
      "epoch 0 total_correct: 41746 loss: 47931.33064651489\n",
      "epoch 1 total_correct: 47666 loss: 32114.571445465088\n",
      "epoch 2 total_correct: 49852 loss: 27725.647327423096\n",
      "epoch 3 total_correct: 50986 loss: 24671.198097229004\n",
      "epoch 4 total_correct: 51786 loss: 22606.401887893677\n",
      "epoch 5 total_correct: 52228 loss: 21156.601266860962\n",
      "epoch 6 total_correct: 52661 loss: 19981.28510093689\n",
      "epoch 7 total_correct: 52968 loss: 19075.926469802856\n",
      "epoch 8 total_correct: 53248 loss: 18281.443408966064\n",
      "epoch 9 total_correct: 53482 loss: 17640.30496406555\n",
      "epoch 0 total_correct: 41675 loss: 48052.969818115234\n",
      "epoch 1 total_correct: 48254 loss: 31455.488609313965\n",
      "epoch 2 total_correct: 50136 loss: 27134.10217475891\n",
      "epoch 3 total_correct: 51220 loss: 24443.70962715149\n",
      "epoch 4 total_correct: 51764 loss: 22657.64875602722\n",
      "epoch 5 total_correct: 52216 loss: 21350.44238471985\n",
      "epoch 6 total_correct: 52592 loss: 20356.156324386597\n",
      "epoch 7 total_correct: 52904 loss: 19473.01555633545\n",
      "epoch 8 total_correct: 53109 loss: 18798.547008514404\n",
      "epoch 9 total_correct: 53351 loss: 18180.20570373535\n",
      "epoch 0 total_correct: 27435 loss: 96164.96783447266\n",
      "epoch 1 total_correct: 41619 loss: 49496.366638183594\n",
      "epoch 2 total_correct: 44337 loss: 41316.16052246094\n",
      "epoch 3 total_correct: 45688 loss: 37338.770263671875\n",
      "epoch 4 total_correct: 46858 loss: 34686.256774902344\n",
      "epoch 5 total_correct: 47702 loss: 32740.98583984375\n",
      "epoch 6 total_correct: 48433 loss: 31167.795989990234\n",
      "epoch 7 total_correct: 49062 loss: 29867.25308227539\n",
      "epoch 8 total_correct: 49546 loss: 28786.40020751953\n",
      "epoch 9 total_correct: 49962 loss: 27874.99234008789\n",
      "epoch 0 total_correct: 29815 loss: 88322.04602050781\n",
      "epoch 1 total_correct: 42659 loss: 45646.99920654297\n",
      "epoch 2 total_correct: 44582 loss: 40001.73809814453\n",
      "epoch 3 total_correct: 45774 loss: 37241.99938964844\n",
      "epoch 4 total_correct: 46657 loss: 35201.988220214844\n",
      "epoch 5 total_correct: 47336 loss: 33528.64929199219\n",
      "epoch 6 total_correct: 48065 loss: 32070.222869873047\n",
      "epoch 7 total_correct: 48705 loss: 30809.07876586914\n",
      "epoch 8 total_correct: 49123 loss: 29758.881805419922\n",
      "epoch 9 total_correct: 49586 loss: 28781.556671142578\n"
     ]
    }
   ],
   "source": [
    "for lr, batch_size, shuffle in product(*param_values):\n",
    "    comment = f' batch_size={batch_size} lr={lr} shuffle={shuffle}'\n",
    "\n",
    "    network = Network()\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    optimizer = optim.Adam(\n",
    "        network.parameters(), lr=lr\n",
    "    )\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "    tb.add_image('images', grid)\n",
    "    tb.add_graph(network, images)\n",
    "\n",
    "    # Training\n",
    "    for epoch in range(10): \n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            images, labels = batch \n",
    "            preds = network(images)\n",
    "            \n",
    "            loss = F.cross_entropy(preds, labels) # loss function\n",
    "            optimizer.zero_grad()                 # set all gradients to zero\n",
    "            \n",
    "            loss.backward()         # calculate gradients, training points are supply constants\n",
    "            optimizer.step()        # update weights to minimize loss (accdg to adam)\n",
    "\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_correct += get_num_correct(preds, labels)\n",
    "        \n",
    "        tb.add_scalar('Loss', total_loss, epoch)\n",
    "        tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "        tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "\n",
    "        for name, weight in network.named_parameters():\n",
    "            tb.add_histogram(name, weight, epoch)\n",
    "            tb.add_histogram(f'{name}.grad', weight.grad, epoch)\n",
    "\n",
    "        print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "\n",
    "    tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}